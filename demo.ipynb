{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from laplace.curvature import KFAC\n",
    "from laplace.sampler import Sampler\n",
    "from experiments import plots\n",
    "from experiments.dataset import F3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-laplace demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1000 # number of training epochs\n",
    "TAU = 10          # Hyperparameter tau\n",
    "N = 100           # Hyperparameter N\n",
    "MC_SAMPLES = 50   # Number of Monte Carlo Samples\n",
    "NUM_CLASSES = 2   # Number of classes in the multi-label-classification example\n",
    "RANDOM_SEED = 666 # Random seed value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Seed random number generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. create training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds = F3.create(50, -5.5, 5.5)\n",
    "training_set = tf.data.Dataset.from_tensor_slices(ds.get()).batch(32)\n",
    "test_set = tf.data.Dataset.from_tensor_slices(ds.get_test_set(2000)).batch(256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. build and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_dim=2, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(10, activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001)),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES)\n",
    "])\n",
    "criterion = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=criterion, optimizer=optimizer, metrics=['accuracy'])\n",
    "model.fit(training_set, epochs=1000, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. approximate curvature and create Bayesian neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kfac = KFAC.compute(model, training_set, criterion)\n",
    "sampler = Sampler.create(kfac, tau=TAU, n=N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. evaluate bnn on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "true_labels = tf.zeros([0, NUM_CLASSES], dtype=tf.int64)\n",
    "points = tf.zeros((0, 2), dtype=tf.float32)\n",
    "predictions = np.zeros([MC_SAMPLES, 0, NUM_CLASSES], dtype=np.float32)\n",
    "for i, (x, y) in enumerate(test_set):\n",
    "    posterior_mean = model.get_weights()\n",
    "    true_labels = tf.concat([true_labels, tf.cast(y, tf.int64)], axis=0)\n",
    "    points = tf.concat([points, tf.cast(x, dtype=tf.float32)], axis=0)\n",
    "    batch_predictions = np.zeros([MC_SAMPLES, x.shape[0], NUM_CLASSES], dtype=np.float32)\n",
    "    for sample in range(MC_SAMPLES):\n",
    "        sampler.sample_and_replace_weights()\n",
    "        batch_predictions[sample] = tf.sigmoid(model.predict(x)).numpy()\n",
    "        model.set_weights(posterior_mean)\n",
    "    predictions = np.concatenate([predictions, batch_predictions], axis=1)\n",
    "    print(f\"Evaluated batch {i+1}/{len(test_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "5. visualise uncertainty as predictive standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plotter = plots.DatasetPlotter(ds)\n",
    "heatmap = plotter.plot_heatmap(points,\n",
    "                               predictions.std(axis=0).sum(axis=1),\n",
    "                               title=f\"predictive standard deviation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
